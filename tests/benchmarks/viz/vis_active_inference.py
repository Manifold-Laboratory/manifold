"""
Professional Active Inference Visualization
===========================================
Mapping how 'Curiosity' and 'Active Inference' warp the manifold topology 
to prioritize novel or high-entropy state transitions.
"""

import torch
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import sys
import os
from pathlib import Path

# Add project root
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from gfn.model import Manifold
from tests.benchmarks.bench_utils import ResultsLogger, PerformanceStats

def visualize_active_inference_distortion(checkpoint_path=None):
    logger = ResultsLogger("active_inference", category="viz")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print("ðŸ§  Visualizing Professional Active Inference Distortion...")
    
    # 1. Setup
    vocab = "0123456789+-*= "
    physics_config = {
        'embedding': {'type': 'functional', 'mode': 'binary', 'coord_dim': 16},
        'active_inference': {'enabled': True}
    }
    model = Manifold(vocab_size=len(vocab), dim=512, depth=1, heads=1, physics_config=physics_config).to(device)
    
    if checkpoint_path and os.path.exists(checkpoint_path):
        try:
            ckpt = torch.load(checkpoint_path, map_location=device)
            state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
            model.load_state_dict(state_dict, strict=False)
            print("âœ“ Checkpoint loaded")
        except:
            print("âš ï¸ Using random weights")
            
    model.eval()
    layer = model.layers[0]
    manifold_macro = layer.macro_manifold
    
    # 2. Render Adaptive Curvature
    grid_res = 45
    lim = 3.5
    xv, yv = np.linspace(-lim, lim, grid_res), np.linspace(-lim, lim, grid_res)
    X, Y = np.meshgrid(xv, yv)
    
    v_batch = torch.zeros(grid_res*grid_res, 512).to(device)
    for i in range(grid_res):
        for j in range(grid_res):
            v_batch[i*grid_res+j, 0], v_batch[i*grid_res+j, 1] = X[i, j], Y[i, j]
            
    # Simulate Contexts: One 'Neutral', one 'Curious' (High surprise at origin)
    x_neutral = torch.zeros(1, 512).to(device)
    # Simulation of internal state that triggers intense local curvature (Singularity)
    x_curious = torch.randn(1, 512).to(device) * 2.0 

    fig, axes = plt.subplots(1, 2, figsize=(18, 8))
    
    with torch.no_grad():
        # Scenario A: Homogeneous / Baseline
        mag_n = torch.norm(manifold_macro.christoffels[0](v_batch, x=x_neutral), dim=-1).view(grid_res, grid_res).cpu().numpy()
        im1 = axes[0].imshow(mag_n, extent=[-lim, lim, -lim, lim], cmap='icefire', origin='lower')
        axes[0].set_title("Manifold State A: Equilibrium (Passive)", fontsize=15, fontweight='bold')
        fig.colorbar(im1, ax=axes[0], label='Background Curvature')

        # Scenario B: Distorted / Singular
        mag_c = torch.norm(manifold_macro.christoffels[0](v_batch, x=x_curious), dim=-1).view(grid_res, grid_res).cpu().numpy()
        im2 = axes[1].imshow(mag_c, extent=[-lim, lim, -lim, lim], cmap='icefire', origin='lower')
        axes[1].set_title("Manifold State B: Adaptive Distortion (Active)", fontsize=15, fontweight='bold')
        fig.colorbar(im2, ax=axes[1], label='Curiosity Potential')

    fig.suptitle("Active Inference: Dynamic Manifold Warp", fontsize=22, fontweight='bold', y=0.98)
    logger.save_plot(fig, "active_inference_warp.png")
    
    # 3. Metrics
    logger.save_json({
        "plasticity_delta": float(np.mean(mag_c) - np.mean(mag_n)),
        "max_singularity_depth": float(np.max(mag_c)),
        "active_response": "High (Localized Geometric Focus)"
    })
    
    print(f"âœ“ Active Inference Analysis Complete. Peak Distortion: {np.max(mag_c):.4f}")

if __name__ == "__main__":
    ckpt = sys.argv[1] if len(sys.argv) > 1 else None
    visualize_active_inference_distortion(ckpt)
